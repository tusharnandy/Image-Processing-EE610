{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute = r\"C:\\Users\\Tushar\\Desktop\\Experiments\\weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGlobal Variables in the code:\\nimage: current image or the variation which is displayed\\nimage_array: stack of images and variations created after browsing\\naction_array: stack of strings having names of operations till now\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image\n",
    "import PIL.Image as pil_image\n",
    "import tkinter.font as font\n",
    "import cv2\n",
    "import warnings\n",
    "from functools import partial\n",
    "warnings.filterwarnings('ignore')\n",
    "from tkinter import filedialog\n",
    "import torch\n",
    "from models import RDN\n",
    "\n",
    "\"\"\"\n",
    "Global Variables in the code:\n",
    "image: current image or the variation which is displayed\n",
    "image_array: stack of images and variations created after browsing\n",
    "action_array: stack of strings having names of operations till now\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_img():     \n",
    "    \"\"\"\n",
    "    Function to get an image from PC\n",
    "    \"\"\"\n",
    "    global image, image_array, action_array\n",
    "    path = filedialog.askopenfilename(title='open', filetypes = ((\"PNG Files\", \"*.png*\"), (\"JPG Files\", \"*.jpg*\")))\n",
    "    #gets the path of the file from pc\n",
    "    if path != ():\n",
    "        image = cv2.imread(path) #image is a numpy ndarray now\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #convert to RGB\n",
    "        PIL_image = Image.fromarray(image.astype('uint8'), 'RGB') #converted to PIL\n",
    "        Tk_image = ImageTk.PhotoImage(PIL_image) #converted to ImageTk for compatibility with GUI framework\n",
    "        panel.configure(image = Tk_image, bd = 10) #place image in the panel\n",
    "        panel.image = Tk_image #place image in the panel\n",
    "        action_array = [\"Browse\"] #save info of last action in stack for display\n",
    "        last[\"text\"] = \"Browse\" #will be displayed\n",
    "        image_array = [] #stack for storing images and variations\n",
    "        image_array.append(image) #store image in stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undo(): \n",
    "    global image ,image_array, action_array\n",
    "    if len(image_array) > 1: #execute only if some action has been done\n",
    "        image_array.pop() #returns (pops) last element of the stack\n",
    "        image = image_array[-1] #new last element after popping\n",
    "        action_array.pop() #pops last element of action stack\n",
    "        last['text'] = action_array[-1] #new last action\n",
    "        PIL_image = Image.fromarray(image.astype('uint8'), 'RGB') #converted to PIL\n",
    "        Tk_image = ImageTk.PhotoImage(PIL_image) #converted to ImageTk\n",
    "        panel.configure(image = Tk_image)  #configure previous (now current) image\n",
    "        panel.image = Tk_image        #image placed on the panel \n",
    "\n",
    "def undo_all():\n",
    "    global image ,image_array, action_array\n",
    "    if len(image_array) > 1:  #execute only if some action has been done\n",
    "        image = image_array[0] #original image\n",
    "        image_array = [image] #singleton list of original image\n",
    "        action_array = [action_array[0]] #singleton list of 'Browse' action \n",
    "        last['text'] = action_array[0] #display 'Browse'\n",
    "        PIL_image = Image.fromarray(image.astype('uint8'), 'RGB') #converted to PIL\n",
    "        Tk_image = ImageTk.PhotoImage(PIL_image) #converted to ImageTk\n",
    "        panel.configure(image = Tk_image) #configure original image\n",
    "        panel.image = Tk_image #original image placed on panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/57033158/how-to-save-images-with-the-save-button-on-the-tkinter-in-python\n",
    "def save_as():\n",
    "    \"\"\"\n",
    "    Function to save the modified image in any location in the device\n",
    "    \"\"\"\n",
    "    global image\n",
    "    path = filedialog.asksaveasfile(defaultextension=\".png\") #gets the path to location\n",
    "    if path is None:  #if not chosen any path\n",
    "        return\n",
    "    PIL_image = Image.fromarray(image.astype('uint8'), 'RGB') #convert to PIL image\n",
    "    PIL_image.save(path.name) #save the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_thresh_value():\n",
    "    \"\"\"\n",
    "    Creates a window and takes user input for the threshold value\n",
    "    \"\"\"\n",
    "    frame_t = tk.Tk() #new window\n",
    "    frame_t.title(\"Enter Threshold Value\") #title\n",
    "    frame_t.geometry('300x80') #dimensions\n",
    "    global thresh_entry  #variable to hold input ksize\n",
    "    thresh_entry = tk.Text(frame_t, width = 10, height = 2, relief = 'solid', font = ('Comic Sans', 20)) #place to write input, for user\n",
    "    thresh_entry.place(relx = 0, rely = 0) #positioning relative to borders\n",
    "    thresh_btn = tk.Button(frame_t, text = 'Apply', command = partial(thresholding_gradient,frame_t),\n",
    "                        height = 1, font = ('Arial', 12, \"bold\"), relief = 'raised') #user will press this button after typing\n",
    "    thresh_btn.place(relx = 0.65, rely = 0.6) #positioning relative to borders\n",
    "    frame_t.mainloop() # Window loops and waits for events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_balanced(org_img, r = 1, g = 1, b = 1, c = 1):\n",
    "    image = org_img.copy()\n",
    "    image[:,:,0] = image[:,:,0] * r \n",
    "    image[:,:,1] = image[:,:,1] * g\n",
    "    image[:,:,2] = image[:,:,2] * b\n",
    "    return image\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sobelx = np.array([[-1, 0, 1],\n",
    "                   [-2, 0, 2],\n",
    "                   [-1, 0 ,1]], np.float32)\n",
    "sobely = np.array([[-1,-2,-1],\n",
    "                   [0, 0 ,0],\n",
    "                   [1, 2, 1]], np.float32)\n",
    "gaussian = np.array([[1, 2, 1],\n",
    "                    [2, 4 ,2],\n",
    "                    [1, 2, 1]], np.float32) / 16\n",
    "\n",
    "#Hysterisis Thresholding\n",
    "def hist_thresh(pixel, th = 50, tl = 20):\n",
    "    if pixel >= th:\n",
    "        pixel = 255\n",
    "    elif pixel >= tl:\n",
    "        pixel = 20\n",
    "    else:\n",
    "        pixel = 0\n",
    "    return pixel\n",
    "v_hist_thresh = np.vectorize(hist_thresh)\n",
    "\n",
    "#binary thresholding\n",
    "def binary_thresh(pixel, t = 127):\n",
    "    if pixel >= t:\n",
    "        pixel = 255\n",
    "    else:\n",
    "        pixel = 0\n",
    "    return pixel\n",
    "\n",
    "v_binary_thresh = np.vectorize(binary_thresh)\n",
    "\n",
    "#Functionalising the whole code\n",
    "def canny_edge_detector(th = 50, tl = 25, color = True):\n",
    "    global image, image_array, action_array\n",
    "    arr=  np.array(image).copy()\n",
    "    if color:\n",
    "        org_red = arr[:,:,0]\n",
    "        org_green = arr[:,:,1]\n",
    "        org_blue = arr[:,:,2]\n",
    "\n",
    "        G_arr = np.zeros(org_red.shape)\n",
    "        theta_arr = np.zeros(org_red.shape) \n",
    "        dRdx = np.zeros(org_red.shape)\n",
    "        dRdy = np.zeros(org_red.shape)\n",
    "        dGdx = np.zeros(org_red.shape)\n",
    "        dGdy = np.zeros(org_red.shape)\n",
    "        dBdx = np.zeros(org_red.shape)\n",
    "        dBdy = np.zeros(org_red.shape)\n",
    "        red = org_red.copy()\n",
    "        green = org_green.copy()\n",
    "        blue = org_blue.copy()\n",
    "        \n",
    "        #smoothing with Gaussian kernel\n",
    "        red = signal.convolve2d(org_red, gaussian)\n",
    "        green = signal.convolve2d(org_green, gaussian)\n",
    "        blue = signal.convolve2d(org_blue, gaussian)\n",
    "\n",
    "        #calculating gradient using convolution with Sobel operators      \n",
    "        dRdx = signal.convolve2d(red ,sobelx)\n",
    "        dRdy = signal.convolve2d(red , sobely)\n",
    "        dGdx = signal.convolve2d(green, sobelx)\n",
    "        dGdy = signal.convolve2d(green, sobely)\n",
    "        dBdx = signal.convolve2d(blue, sobelx)\n",
    "        dBdy = signal.convolve2d(blue, sobely)\n",
    "        gxx = abs(dRdx)**2 + abs(dGdx)**2 + abs(dBdx)**2\n",
    "        gyy = abs(dRdy)**2 + abs(dGdy)**2 + abs(dBdy)**2\n",
    "        gxy = dRdx*dRdy + dGdx*dGdy + dBdx*dBdy \n",
    "        theta_arr = 0.5*np.arctan2(2*gxy, gxx - gyy)\n",
    "        G_arr = np.sqrt(0.5*(gxx + gyy + (gxx-gyy)*np.cos(2*theta_arr) + 2*gxy*np.sin(2*theta_arr)))\n",
    "    \n",
    "    else: #if grayscale image or user wants use of intensity channel\n",
    "        if len(arr.shape) == 3:  \n",
    "            org_red = arr[:,:,0]\n",
    "            org_green = arr[:,:,1]\n",
    "            org_blue = arr[:,:,2]\n",
    "            org_arr = sum([org_red,org_green,org_blue])/3  #intensity\n",
    "        \n",
    "        dFdx = np.zeros(org_arr.shape)\n",
    "        dFdy = np.zeros(org_arr.shape)\n",
    "        new_arr = org_arr.copy()\n",
    "        #smoothing with Gaussian kernel\n",
    "        new_arr = signal.convolve2d(org_arr, gaussian)\n",
    "        \n",
    "        #calculating gradient using convolution with Sobel operators      \n",
    "        dFdx = signal.convolve2d(new_arr, sobelx)\n",
    "        dFdy = signal.convolve2d(new_arr, sobely)\n",
    "        G_arr = np.sqrt(dFdx **2 + dFdy ** 2)\n",
    "        theta_arr = np.arctan2(dFdy, dFdx)\n",
    "        \n",
    "    G_arr = G_arr * 255 / G_arr.max()  #scale grad values to range [0,255]\n",
    "    Gn = np.zeros(G_arr.shape, dtype=np.int32)\n",
    "    angle = theta_arr * 180. / np.pi  #convert to degrees\n",
    "    \n",
    "    for i in range(1,arr.shape[0]-1):\n",
    "        for j in range(1,arr.shape[1]-1):\n",
    "\n",
    "            q = 255 #will hold grad value of first neighbour\n",
    "            r = 255 #will hold grad value of second neighbour\n",
    "            theta = angle[i,j]\n",
    "\n",
    "            #Four types of edge directions: Horizontal, Vertical, +45 deg, -45 deg\n",
    "            #Digital Image Processing by Gonzalez and Woods, page 731\n",
    "            if (-180 <= theta < -157.5) or (-22.5 <= theta < 22.5) or (157.5 <= theta <= 180):\n",
    "                q = G_arr[i, j+1]\n",
    "                r = G_arr[i, j-1]\n",
    "            elif (22.5 <= theta < 67.5) or (-157.5 <= theta <= -112.5):\n",
    "                q = G_arr[i+1, j-1]\n",
    "                r = G_arr[i-1, j+1]\n",
    "            elif (67.5 <= theta < 112.5) or (-112.5 <= theta < -67.5):\n",
    "                q = G_arr[i+1, j]\n",
    "                r = G_arr[i-1, j]\n",
    "            elif (112.5 <= angle[i,j] < 157.5) or (-67.5 <= theta < -22.5):\n",
    "                q = G_arr[i-1, j-1]\n",
    "                r = G_arr[i+1, j+1]\n",
    "\n",
    "            #if value of grad is more than value of grad at both neighbours \n",
    "            # ... along direction, then set Z = grad at [i,j]\n",
    "            #otherwise set Z = 0 at [i,j]\n",
    "            if (G_arr[i,j] >= q) and (G_arr[i,j] >= r):\n",
    "                Gn[i,j] = G_arr[i,j]\n",
    "            else:\n",
    "                Gn[i,j] = 0\n",
    "                \n",
    "    strong_weak = v_hist_thresh(Gn, th, tl)\n",
    "    final_canny = strong_weak.copy()\n",
    "    for i in range(1, strong_weak.shape[0]-1):\n",
    "        for j in range(1, strong_weak.shape[1]-1):\n",
    "            if (strong_weak[i,j] != 0) and (strong_weak[i,j] != 255): #if weak pixel\n",
    "                final_canny[i,j] = float(255 in strong_weak[i-1:i+2, j-1:j+2]) * 255\n",
    "    \n",
    "    image = final_canny\n",
    "    rgb_PIL = Image.fromarray(image.astype('uint8')) #convert to PIL\n",
    "    rgb_PIL = ImageTk.PhotoImage(rgb_PIL) #convert to PhotoImage\n",
    "    panel.configure(image = rgb_PIL) #configure new image\n",
    "    panel.image = rgb_PIL #place on the panel\n",
    "    image_array.append(image) #store onto the stack\n",
    "    last[\"text\"] = \"Canny Edge Detection\" #Display action\n",
    "    action_array.append(\"Canny Edge Detection\") #store action onto stack\n",
    "\n",
    "\n",
    "def thresholding_gradient(frame_t, color = True):\n",
    "    t = int(thresh_entry.get(1.0, \"end-1c\"))\n",
    "    global image, image_array, action_array\n",
    "    arr=  np.array(image).copy()\n",
    "    if color:\n",
    "        org_red = arr[:,:,0]\n",
    "        org_green = arr[:,:,1]\n",
    "        org_blue = arr[:,:,2]\n",
    "\n",
    "        G_arr = np.zeros(org_red.shape)\n",
    "        theta_arr = np.zeros(org_red.shape) \n",
    "        dRdx = np.zeros(org_red.shape)\n",
    "        dRdy = np.zeros(org_red.shape)\n",
    "        dGdx = np.zeros(org_red.shape)\n",
    "        dGdy = np.zeros(org_red.shape)\n",
    "        dBdx = np.zeros(org_red.shape)\n",
    "        dBdy = np.zeros(org_red.shape)\n",
    "        red = org_red.copy()\n",
    "        green = org_green.copy()\n",
    "        blue = org_blue.copy()\n",
    "        \n",
    "        #smoothing with Gaussian kernel\n",
    "        red = signal.convolve2d(org_red, gaussian)\n",
    "        green = signal.convolve2d(org_green, gaussian)\n",
    "        blue = signal.convolve2d(org_blue, gaussian)\n",
    "\n",
    "        #calculating gradient using convolution with Sobel operators      \n",
    "        dRdx = signal.convolve2d(red ,sobelx)\n",
    "        dRdy = signal.convolve2d(red , sobely)\n",
    "        dGdx = signal.convolve2d(green, sobelx)\n",
    "        dGdy = signal.convolve2d(green, sobely)\n",
    "        dBdx = signal.convolve2d(blue, sobelx)\n",
    "        dBdy = signal.convolve2d(blue, sobely)\n",
    "        gxx = abs(dRdx)**2 + abs(dGdx)**2 + abs(dBdx)**2\n",
    "        gyy = abs(dRdy)**2 + abs(dGdy)**2 + abs(dBdy)**2\n",
    "        gxy = dRdx*dRdy + dGdx*dGdy + dBdx*dBdy \n",
    "        theta_arr = 0.5*np.arctan2(2*gxy, gxx - gyy)\n",
    "        G_arr = np.sqrt(0.5*(gxx + gyy + (gxx-gyy)*np.cos(2*theta_arr) + 2*gxy*np.sin(2*theta_arr)))\n",
    "    \n",
    "    else: #if grayscale image or user wants use of intensity channel\n",
    "        if len(arr.shape) == 3:  \n",
    "            org_red = arr[:,:,0]\n",
    "            org_green = arr[:,:,1]\n",
    "            org_blue = arr[:,:,2]\n",
    "            org_arr = sum([org_red,org_green,org_blue])/3  #intensity\n",
    "        \n",
    "        dFdx = np.zeros(org_arr.shape)\n",
    "        dFdy = np.zeros(org_arr.shape)\n",
    "        new_arr = org_arr.copy()\n",
    "        #smoothing with Gaussian kernel\n",
    "        new_arr = signal.convolve2d(org_arr, gaussian)\n",
    "        \n",
    "        #calculating gradient using convolution with Sobel operators      \n",
    "        dFdx = signal.convolve2d(new_arr, sobelx)\n",
    "        dFdy = signal.convolve2d(new_arr, sobely)\n",
    "        G_arr = np.sqrt(dFdx **2 + dFdy ** 2)\n",
    "        theta_arr = np.arctan2(dFdy, dFdx)\n",
    "        \n",
    "    G_arr = G_arr * 255 / G_arr.max()  #scale grad values to range [0,255]\n",
    "    binary_grad = v_binary_thresh(G_arr, t)\n",
    "    image = binary_grad\n",
    "    rgb_PIL = Image.fromarray(image.astype('uint8')) #convert to PIL\n",
    "    rgb_PIL = ImageTk.PhotoImage(rgb_PIL) #convert to PhotoImage\n",
    "    panel.configure(image = rgb_PIL) #configure new image\n",
    "    panel.image = rgb_PIL #place on the panel\n",
    "    image_array.append(image) #store onto the stack\n",
    "    last[\"text\"] = \"Thresholding Gradient\" #Display action\n",
    "    action_array.append(\"Thresholding Gradient\") #store action onto stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(struct_dim = (5,5)):\n",
    "    global image, image_array, action_array\n",
    "    arr = np.array(image).copy()\n",
    "    if arr.max() == 255:\n",
    "        arr = arr/255\n",
    "    dilated = arr.copy()\n",
    "    h = (struct_dim[0]-1)//2\n",
    "    b = (struct_dim[1]-1)//2\n",
    "    for x in range(1, arr.shape[0]-1):\n",
    "        for y in range(1, arr.shape[1]-1):\n",
    "            if 1 in arr[x-h:x+h+1, y-b:y-b+1]:\n",
    "                dilated[x,y] = 1.0\n",
    "            else:\n",
    "                dilated[x,y] = 0.0\n",
    "#     return dilated\n",
    "    image = dilated * 255\n",
    "    rgb_PIL = Image.fromarray(image.astype('uint8')) #convert to PIL\n",
    "    rgb_PIL = ImageTk.PhotoImage(rgb_PIL) #convert to PhotoImage\n",
    "    panel.configure(image = rgb_PIL) #configure new image\n",
    "    panel.image = rgb_PIL #place on the panel\n",
    "    image_array.append(image) #store onto the stack\n",
    "    last[\"text\"] = \"Dilation\" #Display action\n",
    "    action_array.append(\"Dilation\") #store action onto stack\n",
    "\n",
    "def erode(struct_dim = (5,5)):\n",
    "    global image, image_array, action_array\n",
    "    arr = np.array(image).copy()\n",
    "    if arr.max() == 255:\n",
    "        arr = arr/255\n",
    "    eroded = arr.copy()\n",
    "    h = (struct_dim[0]-1)//2\n",
    "    b = (struct_dim[1]-1)//2\n",
    "    for x in range(1, arr.shape[0]-1):\n",
    "        for y in range(1, arr.shape[1]-1):\n",
    "            if 0 in arr[x-h:x+h+1, y-b:y-b+1]:\n",
    "                eroded[x,y] = 0.0\n",
    "            else:\n",
    "                eroded[x,y] = 1.0\n",
    "#     return eroded\n",
    "    image = eroded * 255\n",
    "    rgb_PIL = Image.fromarray(image.astype('uint8')) #convert to PIL\n",
    "    rgb_PIL = ImageTk.PhotoImage(rgb_PIL) #convert to PhotoImage\n",
    "    panel.configure(image = rgb_PIL) #configure new image\n",
    "    panel.image = rgb_PIL #place on the panel\n",
    "    image_array.append(image) #store onto the stack\n",
    "    last[\"text\"] = \"Erosion\" #Display action\n",
    "    action_array.append(\"Erosion\") #store action onto stack\n",
    "\n",
    "def opening(org_image, struct_dim = (5,5)):\n",
    "    eroded = erode(org_image, struct_dim)\n",
    "    opened = dilate(eroded, struct_dim)\n",
    "    return opened\n",
    "\n",
    "def closing(org_image, struct_dim = (5,5)):\n",
    "    dilated = dilate(org_image, struct_dim)\n",
    "    closed = erode(eroded, struct_dim)\n",
    "    return closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\text{Super-resolution}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of super-resolution is to scale the image to a larger size without degrading the quality of the image. \n",
    "\n",
    "For this task, we utilize a neural network architecure called \"Residual Dense Network\", designed by Zhang et al (paper in refernces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(img): # converts the pixels back to standard scale [0..255]\n",
    "    img = img.mul(255.0).clamp(0.0, 255.0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalex2():\n",
    "    global image, image_array, action_array\n",
    "\n",
    "    model2 = RDN(n=2,    # scaling factor\n",
    "                num_channels=3,     # \n",
    "                G_0=64,    # G_0 : refer report\n",
    "                G=64,     # G\n",
    "                D=16,      # D\n",
    "                C=8).to(device)    # C and send to available device\n",
    "\n",
    "    state_dict = model2.state_dict()\n",
    "    state_keys = [key for key in state_dict.keys()]\n",
    "    for (i, (n, p)) in enumerate(torch.load(r\"C:\\Users\\Tushar\\Desktop\\RDN-pytorch-master\\weights\\rdn_x2.pth\", map_location=lambda storage, loc: storage).items()):\n",
    "        # print(f\"n = {n}, key = {state_keys[i]}\")\n",
    "        state_dict[state_keys[i]].copy_(p)\n",
    "\n",
    "    model2.eval()   # convert model to testing mode\n",
    "\n",
    "    image = Image.fromarray(image)\n",
    "    image_width = (image.width // 2) * 2        # converts image dimensions to nearest multiple of scaling_factor\n",
    "    image_height = (image.height // 2) * 2      # converts image dimensions to nearest multiple of scaling_factor\n",
    "    lr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
    "    lr = np.expand_dims(np.array(lr).astype(np.float32).transpose([2, 0, 1]), 0) / 255.0\n",
    "    lr = torch.from_numpy(lr).to(device)\n",
    "\n",
    "    with torch.no_grad():       # interpolate the new image from original\n",
    "        preds = model2(lr).squeeze(0)\n",
    "    image = denormalize(preds).permute(1, 2, 0).byte().cpu().numpy()\n",
    "\n",
    "    rgb_PIL = Image.fromarray(image.astype('uint8')) #convert to PIL\n",
    "    rgb_PIL = ImageTk.PhotoImage(rgb_PIL) #convert to PhotoImage\n",
    "    panel.configure(image = rgb_PIL) #configure new image\n",
    "    panel.image = rgb_PIL #place on the panel\n",
    "    image_array.append(image) #store onto the stack\n",
    "    last[\"text\"] = \"Scale x2\" #Display action\n",
    "    action_array.append(\"Scale x2\") #store action onto stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalex3():\n",
    "    global image, image_array, action_array\n",
    "\n",
    "    model3 = RDN(n=3,    # scaling factor\n",
    "                num_channels=3,     # \n",
    "                G_0=64,    # G_0 : refer report\n",
    "                G=64,     # G\n",
    "                D=16,      # D\n",
    "                C=8).to(device)    # C and send to available device\n",
    "\n",
    "    state_dict = model3.state_dict()\n",
    "    state_keys = [key for key in state_dict.keys()]\n",
    "    for (i, (n, p)) in enumerate(torch.load(rf\"{absolute}\\rdn_x3.pth\", map_location=lambda storage, loc: storage).items()):\n",
    "        # print(f\"n = {n}, key = {state_keys[i]}\")\n",
    "        state_dict[state_keys[i]].copy_(p)\n",
    "\n",
    "    model3.eval()   # convert model to testing mode\n",
    "\n",
    "    image = Image.fromarray(image)\n",
    "    image_width = (image.width // 2) * 2        # converts image dimensions to nearest multiple of scaling_factor\n",
    "    image_height = (image.height // 2) * 2      # converts image dimensions to nearest multiple of scaling_factor\n",
    "\n",
    "    lr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
    "\n",
    "    lr = np.expand_dims(np.array(lr).astype(np.float32).transpose([2, 0, 1]), 0) / 255.0\n",
    "    lr = torch.from_numpy(lr).to(device)\n",
    "\n",
    "    with torch.no_grad():       # interpolate the new image from original\n",
    "        preds = model3(lr).squeeze(0)\n",
    "    \n",
    "    image = denormalize(preds).permute(1, 2, 0).byte().cpu().numpy()\n",
    "\n",
    "    rgb_PIL = Image.fromarray(image.astype('uint8')) #convert to PIL\n",
    "    rgb_PIL = ImageTk.PhotoImage(rgb_PIL) #convert to PhotoImage\n",
    "    panel.configure(image = rgb_PIL) #configure new image\n",
    "    panel.image = rgb_PIL #place on the panel\n",
    "    image_array.append(image) #store onto the stack\n",
    "    last[\"text\"] = \"Scale x3\" #Display action\n",
    "    action_array.append(\"Scale x3\") #store action onto stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalex4():\n",
    "    global image, image_array, action_array\n",
    "\n",
    "    model4 = RDN(n=4,    # scaling factor\n",
    "                num_channels=3,     # \n",
    "                G_0=64,    # G_0 : refer report\n",
    "                G=64,     # G\n",
    "                D=16,      # D\n",
    "                C=8).to(device)    # C and send to available device\n",
    "\n",
    "    state_dict = model4.state_dict()\n",
    "    state_keys = [key for key in state_dict.keys()]\n",
    "    for (i, (n, p)) in enumerate(torch.load(r\"C:\\Users\\Tushar\\Desktop\\RDN-pytorch-master\\weights\\rdn_x4.pth\", map_location=lambda storage, loc: storage).items()):\n",
    "        # print(f\"n = {n}, key = {state_keys[i]}\")\n",
    "        state_dict[state_keys[i]].copy_(p)\n",
    "\n",
    "    model4.eval()   # convert model to testing mode\n",
    "\n",
    "    image = Image.fromarray(image)\n",
    "    image_width = (image.width // 2) * 2        # converts image dimensions to nearest multiple of scaling_factor\n",
    "    image_height = (image.height // 2) * 2      # converts image dimensions to nearest multiple of scaling_factor\n",
    "\n",
    "    lr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
    "\n",
    "    lr = np.expand_dims(np.array(lr).astype(np.float32).transpose([2, 0, 1]), 0) / 255.0\n",
    "    lr = torch.from_numpy(lr).to(device)\n",
    "\n",
    "    with torch.no_grad():       # interpolate the new image from original\n",
    "        preds = model4(lr).squeeze(0)\n",
    "    \n",
    "    image = denormalize(preds).permute(1, 2, 0).byte().cpu().numpy()\n",
    "\n",
    "    rgb_PIL = Image.fromarray(image.astype('uint8')) #convert to PIL\n",
    "    rgb_PIL = ImageTk.PhotoImage(rgb_PIL) #convert to PhotoImage\n",
    "    panel.configure(image = rgb_PIL) #configure new image\n",
    "    panel.image = rgb_PIL #place on the panel\n",
    "    image_array.append(image) #store onto the stack\n",
    "    last[\"text\"] = \"Scale x4\" #Display action\n",
    "    action_array.append(\"Scale x4\") #store action onto stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/file-explorer-in-python-using-tkinter/\n",
    "# https://stackoverflow.com/questions/10133856/how-to-add-an-image-in-tkinter\n",
    "\n",
    "h = 1000\n",
    "w = 1000\n",
    "\n",
    "root = tk.Tk()  #Main GUI Window\n",
    "root.title('Image Enhancer') #its title\n",
    "root.geometry(\"{}x{}\".format(w,h))  #its dimensions\n",
    "\n",
    "panel = tk.Label(root, background = 'white', relief = 'raised') #panel to display the image. Parent: root\n",
    "panel.pack(side = 'left', anchor = tk.NW) #anchored to top right\n",
    "\n",
    "my_font = font.Font(family='Helvetica', size=18, weight='bold')\n",
    "buttonFrame = tk.Frame(root, width = 100) #creating a frame to hold all the buttons in one place. Parent: root\n",
    "buttonFrame.pack(side = 'top', anchor = tk.NE) #achored to top left corner\n",
    "\n",
    "\n",
    "cannyB = tk.Button(buttonFrame, text = \"Canny Edge Detection\", command = canny_edge_detector, \n",
    "                    height = 1, width = 30, font = my_font, bg = 'orange')\n",
    "threshB = tk.Button(buttonFrame, text = \"Thresholding Gradient\", command = enter_thresh_value, \n",
    "                    height = 1, width = 30, font = my_font, bg = 'orange')\n",
    "erosionB = tk.Button(buttonFrame, text = \"Erosion\", command = erode, \n",
    "                    height = 1, width = 30, font = my_font, bg = 'cyan')\n",
    "dilationB = tk.Button(buttonFrame, text = \"Dilation\", command = dilate, \n",
    "                    height = 1, width = 30, font = my_font, bg = 'cyan')\n",
    "scalex2B = tk.Button(buttonFrame, text = \"Scale x2\", command = scalex2, \n",
    "                    height = 1, width = 30, font = my_font, bg = 'green')\n",
    "scalex3B = tk.Button(buttonFrame, text = \"Scale x3\", command = scalex3, \n",
    "                    height = 1, width = 30, font = my_font, bg = 'green')\n",
    "scalex4B = tk.Button(buttonFrame, text = \"Scale x4\", command = scalex4, \n",
    "                    height = 1, width = 30, font = my_font, bg = 'green')\n",
    "\n",
    "# #defining buttons for every operation with commands having respective function calls. Parent: buttonFrame\n",
    "# #when button is pressed the function under command will be called\n",
    "browseB = tk.Button(buttonFrame, text = \"Browse\", command = select_img, \n",
    "                    height = 1, width = 20, font = my_font, bg = 'lightgreen')\n",
    "saveB = tk.Button(buttonFrame, text = \"Save As\", command = save_as, \n",
    "                  height = 1, width = 20, font = my_font, bg = 'lightgreen')\n",
    "undoB = tk.Button(buttonFrame, text = \"Undo\", command = undo, \n",
    "                  height = 1, width = 20, font = my_font, bg = 'lightpink')\n",
    "undo_allB = tk.Button(buttonFrame, text = \"Undo All\", command = undo_all, \n",
    "                      height = 1, width = 20, font = my_font, bg = 'lightpink')\n",
    "\n",
    "last_label = tk.Label(buttonFrame, text = \"Last Action:\", height = 2, width = 20, font = my_font, bg = 'yellow')\n",
    "last = tk.Label(buttonFrame, text = \"No Action\", height = 2, width = 20, font = my_font,  bg = 'yellow', fg = 'red')\n",
    "# # label to display last action\n",
    "\n",
    "# Some additional instructions displayed through a label and text. Parent: buttonFrame\n",
    "# info_text = '''Click the Browse button to select an image from your system, \n",
    "# apply the necessary method(s) and then save the image using the Save As button.\n",
    "# '''\n",
    "# info = tk.Label(buttonFrame, text = info_text, font = ('Helvetica', 15), height = 15, padx = 5, wraplength = 200)\n",
    "# info.pack(side = 'bottom', fill = 'both') #at the bottom of buttonFrame\n",
    "\n",
    "# #placing all the buttons in the buttonFrame frame\n",
    "browseB.pack()\n",
    "saveB.pack()\n",
    "undoB.pack()\n",
    "undo_allB.pack()\n",
    "# eq_histB.pack()\n",
    "# gamma_correctB.pack()\n",
    "# log_xformB.pack()\n",
    "# blur_button.pack()\n",
    "# sharpen_button.pack()\n",
    "# threshold_button.pack()\n",
    "last_label.pack()\n",
    "last.pack()\n",
    "cannyB.pack()\n",
    "threshB.pack()\n",
    "erosionB.pack()\n",
    "dilationB.pack()\n",
    "scalex2B.pack()\n",
    "scalex3B.pack()\n",
    "scalex4B.pack()\n",
    "\n",
    "\n",
    "root.mainloop() # Window loops and waits for events"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
